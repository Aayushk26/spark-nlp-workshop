{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcrfGVpLv2Xx"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/french/Train-Perceptron-French.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61510,
     "status": "ok",
     "timestamp": 1589301565284,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "AcKqfUfOwBoS",
    "outputId": "fdc80474-dd99-46b6-b434-c4192fc5310e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 65kB/s \n",
      "\u001b[K     |████████████████████████████████| 204kB 46.2MB/s \n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed -q spark-nlp==2.4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0koUdx-qv2X3"
   },
   "source": [
    "# Train POS Tagger in French by Spark NLP\n",
    "### Based on Universal Dependency `UD_French-GSD` version 2.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqaPFY67v2X5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "#Spark ML and SQL\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxoKOXacv2YG"
   },
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79528,
     "status": "ok",
     "timestamp": 1589301583319,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "h3JFtb73v2YI",
    "outputId": "9e4e266e-ae2d-4952-870e-20e942b4f305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.4.5\n",
      "Apache Spark version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOW45P_Wv2YQ"
   },
   "source": [
    "Let's prepare our training datasets containing `token_posTag` like `de_DET`. You can download this data set from Amazon S3:\n",
    "\n",
    "```\n",
    "wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80982,
     "status": "ok",
     "timestamp": 1589301584781,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "8E6rlnU3v2YR",
    "outputId": "73798b3b-165e-4312-e3c7-c6522cce0d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-12 16:39:43--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.146.53\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.146.53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3565213 (3.4M) [text/plain]\n",
      "Saving to: ‘/tmp/UD_French-GSD_2.3.txt’\n",
      "\n",
      "UD_French-GSD_2.3.t 100%[===================>]   3.40M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2020-05-12 16:39:43 (30.3 MB/s) - ‘/tmp/UD_French-GSD_2.3.txt’ saved [3565213/3565213]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgrS-fz7v2YY"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import POS\n",
    "training_data = POS().readDataset(\n",
    "    spark=spark,\n",
    "    path=\"/tmp/UD_French-GSD_2.3.txt\",\n",
    "    delimiter=\"_\",\n",
    "    outputPosCol=\"tags\",\n",
    "    outputDocumentCol=\"document\",\n",
    "    outputTextCol=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89643,
     "status": "ok",
     "timestamp": 1589301593459,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "3p1xcWIjv2Yf",
    "outputId": "f2266862-37ea-43a9-832d-0c0e06a176aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                tags|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Les commotions cé...|[[document, 0, 11...|[[pos, 0, 2, DET,...|\n",
      "|L' œuvre est situ...|[[document, 0, 82...|[[pos, 0, 1, DET,...|\n",
      "|Le comportement d...|[[document, 0, 18...|[[pos, 0, 1, DET,...|\n",
      "|Toutefois , les f...|[[document, 0, 44...|[[pos, 0, 8, ADV,...|\n",
      "|Ismene entre et a...|[[document, 0, 80...|[[pos, 0, 5, PROP...|\n",
      "|je reviendrais av...|[[document, 0, 28...|[[pos, 0, 1, PRON...|\n",
      "|Les forfaits comp...|[[document, 0, 30...|[[pos, 0, 2, DET,...|\n",
      "|Il prévient que d...|[[document, 0, 99...|[[pos, 0, 1, PRON...|\n",
      "|Ils tiraient à ba...|[[document, 0, 43...|[[pos, 0, 2, PRON...|\n",
      "|Le château est en...|[[document, 0, 44...|[[pos, 0, 1, DET,...|\n",
      "|En effet , la bir...|[[document, 0, 10...|[[pos, 0, 1, ADP,...|\n",
      "|Le point final de...|[[document, 0, 15...|[[pos, 0, 1, DET,...|\n",
      "|L' information gé...|[[document, 0, 53...|[[pos, 0, 1, DET,...|\n",
      "|Motivé par la cha...|[[document, 0, 21...|[[pos, 0, 5, VERB...|\n",
      "|Il exploitait un ...|[[document, 0, 12...|[[pos, 0, 1, PRON...|\n",
      "|Plus tard dans la...|[[document, 0, 84...|[[pos, 0, 3, ADV,...|\n",
      "|Ils deviennent al...|[[document, 0, 97...|[[pos, 0, 2, PRON...|\n",
      "|Le chevalier lui ...|[[document, 0, 17...|[[pos, 0, 1, DET,...|\n",
      "|Créée au cours du...|[[document, 0, 15...|[[pos, 0, 4, VERB...|\n",
      "|On ne peut éviter...|[[document, 0, 11...|[[pos, 0, 1, PRON...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CBzSVba-v2Yr"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\\\n",
    "    .setPrefixPattern(\"\\\\A([^\\\\s\\\\p{L}\\\\d\\\\$\\\\.#]*)\")\\\n",
    "    .setSuffixPattern(\"([^\\\\s\\\\p{L}\\\\d]?)([^\\\\s\\\\p{L}\\\\d]*)\\\\z\")\\\n",
    "    .setInfixPatterns([\n",
    "        \"([\\\\p{L}\\\\w]+'{1})\",\n",
    "        \"([\\\\$#]?\\\\d+(?:[^\\\\s\\\\d]{1}\\\\d+)*)\",\n",
    "        \"((?:\\\\p{L}\\\\.)+)\",\n",
    "        \"((?:\\\\p{L}+[^\\\\s\\\\p{L}]{1})+\\\\p{L}+)\",\n",
    "        \"([\\\\p{L}\\\\w]+)\"\n",
    "    ])\n",
    "\n",
    "posTagger = PerceptronApproach() \\\n",
    "    .setNIterations(6) \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"pos\") \\\n",
    "    .setPosCol(\"tags\")\n",
    "    \n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector, \n",
    "    tokenizer,\n",
    "    posTagger\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 256063,
     "status": "ok",
     "timestamp": 1589301759894,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "ozE0ZwKuv2Y2",
    "outputId": "7a21eda7-0737-43a6-dd73-b218660ed8c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64.7 ms, sys: 15.9 ms, total: 80.6 ms\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Let's train our Pipeline by using our training dataset\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVkYWiTZv2Y_"
   },
   "source": [
    "This is our testing DataFrame where we get some sentences in French. We are going to use our trained Pipeline to transform these sentence and predict each token's `Part Of Speech`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vQq_Ps_v2ZA"
   },
   "outputs": [],
   "source": [
    "dfTest = spark.createDataFrame([\n",
    "    \"Je sens qu'entre ça et les films de médecins et scientifiques fous que nous avons déjà vus, nous pourrions emprunter un autre chemin pour l'origine.\",\n",
    "    \"On pourra toujours parler à propos d'Averroès de décentrement du Sujet.\"\n",
    "], StringType()).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNF94YHDv2ZG"
   },
   "outputs": [],
   "source": [
    "predict = model.transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257545,
     "status": "ok",
     "timestamp": 1589301761402,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "o-CU0ituv2ZM",
    "outputId": "338c0073-9b58-44c7-bd19-42ac24c45541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              result|              result|\n",
      "+--------------------+--------------------+\n",
      "|[Je, sens, qu'ent...|[PRON, NOUN, ADP,...|\n",
      "|[On, pourra, touj...|[PRON, VERB, ADV,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.select(\"token.result\", \"pos.result\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mkCYL7tv2ZT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Train-Perceptron-French.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
