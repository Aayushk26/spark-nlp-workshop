{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"ner_dl.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"d86L_FUK4U0O","colab_type":"text"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_dl.ipynb)\n","\n","## 0. Colab Setup"]},{"cell_type":"code","metadata":{"id":"dz7v8B5i6uu5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"0afdb3fa-5a20-4efc-a8ec-683d986f286d","executionInfo":{"status":"ok","timestamp":1589304463026,"user_tz":-120,"elapsed":64398,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["import os\n","\n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed -q pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed -q spark-nlp==2.4.5"],"execution_count":1,"outputs":[{"output_type":"stream","text":["openjdk version \"1.8.0_252\"\n","OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n","OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n","\u001b[K     |████████████████████████████████| 215.7MB 57kB/s \n","\u001b[K     |████████████████████████████████| 204kB 42.7MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 112kB 3.4MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-oTcQcU74U0Q","colab_type":"text"},"source":["## Deep Learning NER\n","\n","In the following example, we walk-through a LSTM NER model training and prediction. This annotator is implemented on top of TensorFlow.\n","\n","This annotator will take a series of word embedding vectors, training CoNLL dataset, plus a validation dataset. We include our own predefined Tensorflow Graphs, but it will train all layers during fit() stage.\n","\n","DL NER will compute several layers of BI-LSTM in order to auto generate entity extraction, and it will leverage batch-based distributed calls to native TensorFlow libraries during prediction. "]},{"cell_type":"markdown","metadata":{"id":"FKf4cQ0s4U0R","colab_type":"text"},"source":["#### 1. Call necessary imports and set the resource folder path."]},{"cell_type":"code","metadata":{"id":"Wejw_DrU4U0S","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","\n","from pyspark.sql import SparkSession\n","from pyspark.ml import Pipeline\n","\n","from sparknlp.annotator import *\n","from sparknlp.common import *\n","from sparknlp.base import *\n","\n","import time\n","import zipfile"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcH7A7yG4U0X","colab_type":"text"},"source":["#### 2. Download CoNLL 2003 data if not present"]},{"cell_type":"code","metadata":{"id":"HwJXvsuR4U0Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b37ee946-1619-43f4-afae-550ca9ecb767","executionInfo":{"status":"ok","timestamp":1589304463929,"user_tz":-120,"elapsed":65291,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["# Download CoNLL 2003 Dataset\n","import os\n","from pathlib import Path\n","import urllib.request\n","url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/\"\n","file_train=\"eng.train\"\n","file_testa= \"eng.testa\"\n","file_testb= \"eng.testb\"\n","# https://github.com/patverga/torch-ner-nlp-from-scratch/tree/master/data/conll2003\n","if not Path(file_train).is_file():   \n","    print(\"Downloading \"+file_train)\n","    urllib.request.urlretrieve(url+file_train, file_train)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading eng.train\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Voa04Sj4U0d","colab_type":"text"},"source":["#### 4. Create the spark session"]},{"cell_type":"code","metadata":{"id":"kdIbj0Mo4U0e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"fcfcf0fa-9ddb-4a1a-9523-5cb71e93a31b","executionInfo":{"status":"ok","timestamp":1589304481559,"user_tz":-120,"elapsed":82899,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["import sparknlp \n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version: \", sparknlp.version())\n","print(\"Apache Spark version: \", spark.version)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Spark NLP version:  2.4.5\n","Apache Spark version:  2.4.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YhRg5VSh4U0j","colab_type":"text"},"source":["#### 6. Load parquet dataset and cache into memory"]},{"cell_type":"code","metadata":{"id":"zaxPfBBJ4U0k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"c59f0ecd-f735-426c-e742-7e3a80ad7a35","executionInfo":{"status":"ok","timestamp":1589304510060,"user_tz":-120,"elapsed":111376,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["from sparknlp.training import CoNLL\n","\n","conll = CoNLL(\n","    documentCol=\"document\",\n","    sentenceCol=\"sentence\",\n","    tokenCol=\"token\",\n","    posCol=\"pos\"\n",")\n","\n","training_data = conll.readDataset(spark, './eng.train')\n","\n","\n","embeddings = WordEmbeddingsModel.pretrained()\\\n",".setOutputCol('embeddings')\n","\n","ready_data = embeddings.transform(training_data)\n","\n","ready_data.show(4)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|                 pos|               label|          embeddings|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n","|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n","| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n","|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|[[word_embeddings...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 4 rows\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qYnYyImW4U0p","colab_type":"text"},"source":["#### 5. Create annotator components with appropriate params and in the right order. The finisher will output only NER. Put everything in Pipeline"]},{"cell_type":"code","metadata":{"id":"3638abOy4U0p","colab_type":"code","colab":{}},"source":["nerTagger = NerDLApproach()\\\n","  .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n","  .setLabelColumn(\"label\")\\\n","  .setOutputCol(\"ner\")\\\n","  .setMaxEpochs(1)\\\n","  .setRandomSeed(0)\\\n","  .setVerbose(0)\\\n","  .setIncludeConfidence(True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHrjgNUq4U0t","colab_type":"text"},"source":["#### 7. Train the NerDLModel. (This will take some time)"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"8gwIpiU74U0u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"d7b02d8a-8717-4bf5-da30-00b9bdf6d0af","executionInfo":{"status":"ok","timestamp":1589304827405,"user_tz":-120,"elapsed":428709,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["start = time.time()\n","print(\"Start fitting\")\n","ner_model = nerTagger.fit(ready_data)\n","print(\"Fitting is ended\")\n","print (time.time() - start)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Start fitting\n","Fitting is ended\n","317.23192048072815\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S86y-YiZ4U0z","colab_type":"text"},"source":["#### 8. Lets predict with the model"]},{"cell_type":"code","metadata":{"id":"ywx7fsIj4U0z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"eba36b3e-facf-4068-ae39-1c207513dc9c","executionInfo":{"status":"ok","timestamp":1589304830310,"user_tz":-120,"elapsed":431603,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["document = DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","sentence = SentenceDetector()\\\n","    .setInputCols(['document'])\\\n","    .setOutputCol('sentence')\n","\n","token = Tokenizer()\\\n","    .setInputCols(['sentence'])\\\n","    .setOutputCol('token')\n","\n","embeddings = WordEmbeddingsModel.pretrained()\\\n",".setOutputCol('embeddings')\n","\n","prediction_pipeline = Pipeline(\n","    stages = [\n","        document,\n","        sentence,\n","        token,\n","        embeddings,\n","        ner_model\n","    ]\n",")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OZgAI4wF4U04","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"f1cf6777-cb1f-425c-eb8d-bb3c224792bf","executionInfo":{"status":"ok","timestamp":1589304831291,"user_tz":-120,"elapsed":432576,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["prediction_data = spark.createDataFrame([[\"Maria is a nice place.\"]]).toDF(\"text\")\n","prediction_data.show()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["+--------------------+\n","|                text|\n","+--------------------+\n","|Maria is a nice p...|\n","+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tw_r0Ris4U08","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"4695ff4e-fe6a-460e-a117-1dda96af9684","executionInfo":{"status":"ok","timestamp":1589304833735,"user_tz":-120,"elapsed":435012,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["prediction_model = prediction_pipeline.fit(prediction_data)\n","prediction_model.transform(prediction_data).show()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|          embeddings|                 ner|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|Maria is a nice p...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Ma...|[[word_embeddings...|[[named_entity, 0...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GZRKCjrt4U0_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"3578416a-f70a-40d5-e835-d46705c7682f","executionInfo":{"status":"ok","timestamp":1589304833963,"user_tz":-120,"elapsed":435232,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["# We can be fast!\n","\n","lp = LightPipeline(prediction_model)\n","result = lp.annotate(\"International Business Machines Corporation (IBM) is an American multinational information technology company headquartered in Armonk.\")\n","list(zip(result['token'], result['ner']))"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('International', 'I-ORG'),\n"," ('Business', 'I-ORG'),\n"," ('Machines', 'I-ORG'),\n"," ('Corporation', 'I-ORG'),\n"," ('(', 'O'),\n"," ('IBM', 'I-ORG'),\n"," (')', 'O'),\n"," ('is', 'O'),\n"," ('an', 'O'),\n"," ('American', 'I-MISC'),\n"," ('multinational', 'O'),\n"," ('information', 'O'),\n"," ('technology', 'O'),\n"," ('company', 'O'),\n"," ('headquartered', 'O'),\n"," ('in', 'O'),\n"," ('Armonk', 'I-LOC'),\n"," ('.', 'O')]"]},"metadata":{"tags":[]},"execution_count":11}]}]}