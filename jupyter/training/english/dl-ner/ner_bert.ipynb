{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "ner_bert.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI3at4LA4TO4",
        "colab_type": "text"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_bert.ipynb)\n",
        "\n",
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQkc9O5V6vJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed -q spark-nlp==2.4.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnbkiY634TO7",
        "colab_type": "text"
      },
      "source": [
        "## Deep Learning NER\n",
        "\n",
        "In the following example, we walk-through a LSTM NER model training and prediction. This annotator is implemented on top of TensorFlow.\n",
        "\n",
        "This annotator will take a series of word embedding vectors, training CoNLL dataset, plus a validation dataset. We include our own predefined Tensorflow Graphs, but it will train all layers during fit() stage.\n",
        "\n",
        "DL NER will compute several layers of BI-LSTM in order to auto generate entity extraction, and it will leverage batch-based distributed calls to native TensorFlow libraries during prediction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5NoZwVw4TO8",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Call necessary imports and set the resource folder path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVMuFdHz4TO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../../')\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "import time\n",
        "import zipfile\n",
        "#Setting location of resource Directory\n",
        "resource_path= \"../../../src/test/resources/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnkqe7Db4TPG",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Download CoNLL 2003 data if not present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtNyZXDc4TPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download CoNLL 2003 Dataset\n",
        "import os\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/\"\n",
        "file_train=\"eng.train\"\n",
        "file_testa= \"eng.testa\"\n",
        "file_testb= \"eng.testb\"\n",
        "# https://github.com/patverga/torch-ner-nlp-from-scratch/tree/master/data/conll2003\n",
        "if not Path(file_train).is_file():   \n",
        "    print(\"Downloading \"+file_train)\n",
        "    urllib.request.urlretrieve(url+file_train, file_train)\n",
        "if not Path(file_testa).is_file():\n",
        "    print(\"Downloading \"+file_testa)\n",
        "    urllib.request.urlretrieve(url+file_testa, file_testa)\n",
        "\n",
        "if not Path(file_testb).is_file():\n",
        "    print(\"Downloading \"+file_testb)\n",
        "    urllib.request.urlretrieve(url+file_testb, file_testb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vmA0JH44TPP",
        "colab_type": "text"
      },
      "source": [
        "#### 3. Create the spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3wvVq-14TPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sparknlp \n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxv7jokO4TPY",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Load dataset and cache into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeuwKgWB4TPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BO6oz8i4TPh",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Create annotator components with appropriate params and in the right order. The finisher will output only NER. Put everything in Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxArxJq_4TPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertEmbeddings.pretrained() \\\n",
        " .setInputCols([\"sentence\", \"token\"])\\\n",
        " .setOutputCol(\"bert\")\\\n",
        " .setCaseSensitive(False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMEx77d3bVpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP9nXTCl4TPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# WARNING: This STEP is slow and might crash your system -- High end hardware and/or GPU required\n",
        "## dataframe.cache() does not solve this. Results must be serialized to disk for maximum efficiency\n",
        "### You might need to restart your driver after this step finishes\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "with_bert_path = \"./with_bert.parquet\"\n",
        "\n",
        "if not Path(with_bert_path).is_dir():\n",
        "    bert.transform(training_data)#.write.parquet(\"./with_bert.parquet\")\n",
        "\n",
        "# training_with_bert = spark.read.parquet(\"./with_bert.parquet\").cache()\n",
        "\n",
        "# print(training_with_bert.count())\n",
        "# training_with_bert.select(\"token\", \"bert\").show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewZNMRkX4TPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(1)\\\n",
        "  .setRandomSeed(0)\\\n",
        "  .setVerbose(0)\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    nerTagger,\n",
        "    converter\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmrxa0zb4TP5",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Train the pipeline. (This will take some time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1EsnzJD4TP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "start = time.time()\n",
        "print(\"Start fitting\")\n",
        "model = pipeline.fit(training_with_bert)\n",
        "print(\"Fitting is ended\")\n",
        "print (time.time() - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N13yqmUu4TQA",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Lets predict with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc9NJ1EV4TQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        bert,\n",
        "        model\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07EWw0mG4TQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_data = spark.createDataFrame([[\"Germany is a nice place\"]]).toDF(\"text\")\n",
        "prediction_data.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50yCGM6F4TQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model = prediction_pipeline.fit(prediction_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHk2VbE_4TQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "lp = LightPipeline(prediction_model)\n",
        "result = lp.annotate(\"International Business Machines Corporation (IBM) is an American multinational information technology company headquartered in Armonk.\")\n",
        "for e in list(zip(result['token'], result['ner'])):\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwNEGQts4TQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# This might take 8 minutes. Timing is not lineal\n",
        "\n",
        "prediction_model.transform(prediction_data).show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxYs7v3F4TQq",
        "colab_type": "text"
      },
      "source": [
        "#### 8. Save both pipeline and single model once trained, on disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDk4xWbT4TQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model.write().overwrite().save(\"./ner_dl_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzvHfHBr4TQx",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Load both again, deserialize from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARYxI8594TQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml import PipelineModel, Pipeline\n",
        "\n",
        "loaded_prediction_model = PipelineModel.read().load(\"./ner_dl_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfVgn3ZI4TQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "lp = LightPipeline(loaded_prediction_model)\n",
        "result = lp.annotate(\"Peter is a good person.\")\n",
        "for e in list(zip(result['token'], result['ner']))[:10]:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpDPutD_4TQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for stage in loaded_prediction_model.stages:\n",
        "    print(stage)\n",
        "print(loaded_prediction_model.stages[-1].stages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH191rNe4TRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}