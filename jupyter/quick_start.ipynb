{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "spark_nlp_2.4.4",
      "language": "python",
      "name": "spark_nlp_2.4.4"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "quick_start.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8JHELbJTRlw",
        "colab_type": "text"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/quick_start.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2gbyYe9TRly",
        "colab_type": "text"
      },
      "source": [
        "# Spark NLP Quick Start\n",
        "### How to use Spark NLP pretrained pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx8GKMsUbbSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "78445c0d-3b8f-4dea-ea50-86f1a079d4be"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed -q spark-nlp==2.4.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 56kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 51.6MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 112kB 4.9MB/s \n",
            "\u001b[?25hopenjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1_3lypqTRl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "32239160-0c5c-4a0f-a83d-2d35449c77cc"
      },
      "source": [
        "import sparknlp \n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.4.5\n",
            "Apache Spark version:  2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piF4liZZTRmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1OadFjMTRmo",
        "colab_type": "text"
      },
      "source": [
        "Let's use Spark NLP pre-trained pipeline for `named entity recognition`\n",
        "\n",
        "`NOTE`: if you are using `Windows` please use this pipeline instead: `recognize_entities_dl_noncontrib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA1Saw3qTRmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9edc1aa2-1fd0-4ce1-9515-87c9e141b932"
      },
      "source": [
        "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 159 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtSviSpXTRm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('Google has announced the release of a beta version of the popular TensorFlow machine learning library.') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoBxRzGBTRm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee8539c7-821d-4dc3-ed65-92cb23bd9606"
      },
      "source": [
        "print(result['ner'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANHeKPVTRnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92a501f9-95ea-4ccc-ea4f-8dd5d3d29bca"
      },
      "source": [
        "print(result['entities'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Google', 'TensorFlow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiIpiZHkTRnL",
        "colab_type": "text"
      },
      "source": [
        "Let's use Spark NLP pre-trained pipeline for `sentiment` analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1NgO9-vTRnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0b4d156e-495c-471c-97a0-95ca6605805a"
      },
      "source": [
        "pipeline = PretrainedPipeline('analyze_sentiment', 'en') "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh3isgBmTRnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('This is a very boring movie. I recommend others to awoid this movie is not good..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDsuVeL7TRnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feafc5ba-b69d-4b3e-ef50-d6d0473dbfd6"
      },
      "source": [
        "print(result['sentiment'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative', 'negative', 'negative']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X942sLnUTRne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74756e0a-94c8-4ba4-ef68-cff0ad56ef24"
      },
      "source": [
        "print(result['checked'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'is', 'a', 'very', 'boring', 'movie', '.', 'I', 'recommend', 'others', 'to', 'avoid', 'this', 'movie', 'is', 'not', 'good', '.', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRgDI3k2TRnj",
        "colab_type": "text"
      },
      "source": [
        "The word `awoid` has been corrected to `avoid` by spell checker insdie this pipeline"
      ]
    }
  ]
}