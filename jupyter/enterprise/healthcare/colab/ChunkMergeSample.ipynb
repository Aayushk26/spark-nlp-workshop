{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/colab/ChunkMergeSample.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MdE588BiY3z1",
    "outputId": "85d808ef-8b07-4819-8aab-05618f272d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['secret', 'SPARK_NLP_LICENSE', 'JSL_OCR_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('keys.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "FVFdvGChZDDP",
    "outputId": "ecd2fc38-9b22-4079-8290-9728738d1689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/l5rISdi5Xk\n",
      "Collecting spark-nlp-jsl==2.5.0\n",
      "  Downloading https://pypi.johnsnowlabs.com/l5rISdi5Xk/spark-nlp-jsl/spark_nlp_jsl-2.5.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pyspark==2.4.4 in /usr/local/lib/python3.6/dist-packages (from spark-nlp-jsl==2.5.0) (2.4.4)\n",
      "Collecting spark-nlp==2.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/b0/f50d169c49f5982f8be9e86e285b53e23f91fd7db0d10646c2d1de5c3ad0/spark_nlp-2.5.0-py2.py3-none-any.whl (120kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 7.8MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark==2.4.4->spark-nlp-jsl==2.5.0) (0.10.7)\n",
      "Installing collected packages: spark-nlp, spark-nlp-jsl\n",
      "Successfully installed spark-nlp-2.5.0 spark-nlp-jsl-2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "secret = license_keys['secret']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "! python -m pip install --upgrade spark-nlp-jsl==2.5.0  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed -q spark-nlp==2.5\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "print (sparknlp.version())\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "\n",
    "\n",
    "def start(secret):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.0\") \\\n",
    "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-2.5.0.jar\")\n",
    "      \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "\n",
    "spark = start(secret) # if you want to start the session with custom params as in start function above\n",
    "# sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zgsiTxjaiMd"
   },
   "outputs": [],
   "source": [
    "data_chunk_merge = spark.createDataFrame([\n",
    "  (1,\"Zacarias Woods would not have T2N1 at Los Angeles California\",),\n",
    "  (2,\"Andre Agassi had 2 x 3 x 1 mm hairwig better than T1N2M1\",)\n",
    "]).toDF(\"id\",\"text\")\n",
    "\n",
    "regex = '''(c|p|yc|yp|r|rp|a)?(C[1-5])?M(x|X|0|1[a-d]?),pM\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?N(x|X|0|[1-3][a-d]?),pN\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?T(x|X|is|0|[1-4][a-d]?),pT\n",
    "([0-9]+(\\.[0-9]+)?\\s?x\\s?)*([0-9]+(\\.[0-9]+)?)\\s?(mg|MG|mm|cm|MM|CM|),SIZE\n",
    "at Los Angeles California,LOCATION\n",
    "Zacarias,PERSON\n",
    "better than,BLOCK'''\n",
    "\n",
    "with open('ner_regex.csv', 'w') as f:\n",
    "    f.write(regex)\n",
    "\n",
    "replace_dict = '''pT,TNM\n",
    "pM,TNM'''\n",
    "\n",
    "with open('replace_dict.csv', 'w') as f:\n",
    "    f.write(replace_dict)\n",
    "\n",
    "false_positives = '''beautiful thing,BLOCK'''\n",
    "\n",
    "with open('false_positives.csv', 'w') as f:\n",
    "    f.write(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "weY5V9h7ZDf0",
    "outputId": "972b4569-744e-48dd-9471-920eb4d3e5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "Approximate size to download 14 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "da = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sd = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
    "tk = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")\n",
    "emb = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\").setOutputCol(\"embs\")\n",
    "ner = NerDLModel.pretrained(\"ner_deid_large\",\"en\",\"clinical/models\").setInputCols(\"sentence\",\"token\",\"embs\").setOutputCol(\"ner\")\n",
    "nc = NerConverter().setInputCols(\"sentence\",\"token\",\"ner\").setOutputCol(\"ner_chunk\")\n",
    "rex = RegexMatcher().setInputCols(\"sentence\").setOutputCol(\"rex\").setExternalRules(\"ner_regex.csv\",\",\",\"TEXT\")\n",
    "merger = ChunkMergeApproach().setInputCols(\"ner_chunk\",\"rex\").setOutputCol(\"combined\")\\\n",
    "    .setFalsePositivesResource(\"false_positives.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
    "    .setReplaceDictResource(\"replace_dict.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
    "\n",
    "pl = Pipeline().setStages([da,sd,tk,emb,ner,nc,rex,merger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pl.fit(data_chunk_merge).transform(data_chunk_merge).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "ogbBOST6aZTt",
    "outputId": "d8aff6ec-5976-4340-b002-c96adbe72e1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------------+--------+\n",
      "|id |begin|ner_chunk             |entity  |\n",
      "+---+-----+----------------------+--------+\n",
      "|1  |0    |Zacarias Woods        |NAME    |\n",
      "|1  |38   |Los Angeles California|LOCATION|\n",
      "|2  |0    |Andre Agassi          |NAME    |\n",
      "+---+-----+----------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(arrays_zip(ner_chunk.begin,ner_chunk.result, ner_chunk.metadata)) as a\")\\\n",
    ".selectExpr(\"id\",\"a['0'] as begin\",\"a['1'] as ner_chunk\",\"a['2'].entity as entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------------------------+--------+\n",
      "|id |begin|ner_chunk                |entity  |\n",
      "+---+-----+-------------------------+--------+\n",
      "|1  |0    |Zacarias                 |PERSON  |\n",
      "|1  |30   |T2                       |pT      |\n",
      "|1  |31   |2                        |SIZE    |\n",
      "|1  |32   |N1                       |pN      |\n",
      "|1  |33   |1                        |SIZE    |\n",
      "|1  |35   |at Los Angeles California|LOCATION|\n",
      "|2  |17   |2 x 3 x 1 mm             |SIZE    |\n",
      "|2  |38   |better than              |BLOCK   |\n",
      "|2  |50   |T1                       |pT      |\n",
      "|2  |51   |1                        |SIZE    |\n",
      "|2  |52   |N2                       |pN      |\n",
      "|2  |53   |2                        |SIZE    |\n",
      "|2  |54   |M1                       |pM      |\n",
      "|2  |55   |1                        |SIZE    |\n",
      "+---+-----+-------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(arrays_zip(rex.begin,rex.result, rex.metadata)) as a\")\\\n",
    ".selectExpr(\"id\",\"a['0'] as begin\",\"a['1'] as ner_chunk\",\"a['2'].identifier as entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpLba4tAbPiW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+--------+\n",
      "|id |chunk                    |entity  |\n",
      "+---+-------------------------+--------+\n",
      "|1  |Zacarias Woods           |NAME    |\n",
      "|1  |T2                       |TNM     |\n",
      "|1  |N1                       |pN      |\n",
      "|1  |at Los Angeles California|LOCATION|\n",
      "|2  |Andre Agassi             |NAME    |\n",
      "|2  |2 x 3 x 1 mm             |SIZE    |\n",
      "|2  |better than              |BLOCK   |\n",
      "|2  |T1                       |TNM     |\n",
      "|2  |N2                       |pN      |\n",
      "|2  |M1                       |TNM     |\n",
      "+---+-------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(arrays_zip(combined.result, combined.metadata)) as a\")\\\n",
    ".selectExpr(\"id\",\"a['0'] as chunk\",\"a['1'].entity as entity\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jsl250",
   "language": "python",
   "name": "jsl250"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
