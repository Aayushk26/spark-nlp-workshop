{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please make sure you have SparkNLP 2.4.5 and SparkNLP Enterprise 2.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import StringIndexerModel\n",
    "from pyspark.ml.classification import OneVsRestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp_jsl.start(\"####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = concepts = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"../../../data/resolution/snomed_sample.csv\")\\\n",
    ".withColumn(\"term\", F.expr(\"lower(term)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_chars = [\"'\",\",\",\"/\",\" \",\".\",\"|\",\"@\",\"#\",\"%\",\"&\",\"$\",\"[\",\"]\",\"(\",\")\",\"-\",\";\",\"=\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docAssembler = DocumentAssembler().setInputCol(\"term\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols(\"document\").setOutputCol(\"token\")\\\n",
    "    .setSplitChars(tokenizer_chars)\n",
    "\n",
    "pipelineModel = Pipeline().setStages([docAssembler, tokenizer]).fit(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embeddingsModel = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"document\", \"token\")\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2Chunk = Doc2Chunk().setInputCols(\"document\").setOutputCol(\"chunk\")\n",
    "\n",
    "chunkEmbeddings = ChunkEmbeddings()\\\n",
    "    .setInputCols(\"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"chunk_embeddings\")\n",
    "\n",
    "pipelineChunkEmbeddings = PipelineModel([doc2Chunk, chunkEmbeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_embedded = PipelineModel([pipelineModel, embeddingsModel, pipelineChunkEmbeddings]).transform(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_embedded.write.mode(\"overwrite\").save(\"data/concepts_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_embedded = spark.read.load(\"data/concepts_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9727644122164317"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check embeddings coverage\n",
    "concepts_embedded.selectExpr(\"conceptId\",\"explode(embeddings) as embs\")\\\n",
    ".selectExpr(\"conceptId\",\"case when embs.metadata.isOOV=='false' then 1 else 0 end as coverage\")\\\n",
    ".groupby(\"conceptId\").agg(F.expr(\"avg(coverage) as cov\")).orderBy(\"cov\").toPandas()[\"cov\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_distribution = concepts_embedded.selectExpr(\"explode(token.result) as word\").groupby(\"word\").count()\n",
    "#word_distribution.orderBy(\"count\",ascending=True).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_distribution.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolve_snomed_clinical_l1 download started this may take some time.\n",
      "Approximate size to download 15.3 MB\n",
      "[OK!]\n",
      "resolve_snomed_clinical_l2 download started this may take some time.\n",
      "Approx size to download 583.4 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChunkEntityResolverSelector_d41a7a88595b"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SNOMED Resolution\n",
    "snomed_resolution = \\\n",
    "    EnsembleEntityResolverModel.pretrained(\"ensembleresolve_snomed_clinical\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols(\"ner_token\",\"ner_chunk_embeddings\").setOutputCol(\"snomed_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "transformed_full = snomed_resolution.transform(concepts_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_alternatives = transformed_full\\\n",
    "    .withColumn(\"resolution\",F.expr(\"split(snomed_code.metadata[0]['all_k_results'],':|:')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaled = with_alternatives\\\n",
    "    .withColumn(\"good\", F.expr(\"case when conceptId=snomed_code.result[0] then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat5\", F.expr(\"case when array_contains(slice(resolution, 1, 5), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat10\", F.expr(\"case when array_contains(slice(resolution, 1, 10), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat20\", F.expr(\"case when array_contains(slice(resolution, 1, 20), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat30\", F.expr(\"case when array_contains(slice(resolution, 1, 30), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat500\", F.expr(\"case when array_contains(slice(resolution, 1, 500), conceptId) then 1 else 0 end\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+----+----+-----+-----+-----+------+-----+\n",
      "|topTerm                                                      |good|hat5|hat10|hat20|hat30|hat500|total|\n",
      "+-------------------------------------------------------------+----+----+-----+-----+-----+------+-----+\n",
      "|Procedure (procedure)                                        |0.91|0.93|0.93 |0.93 |0.93 |0.93  |738  |\n",
      "|Finding by site (finding)                                    |0.72|0.73|0.74 |0.74 |0.74 |0.74  |722  |\n",
      "|Body structure (body structure)                              |0.9 |0.92|0.92 |0.92 |0.92 |0.92  |489  |\n",
      "|Organism (organism)                                          |0.49|0.55|0.57 |0.57 |0.57 |0.57  |345  |\n",
      "|Disease (disorder)                                           |0.68|0.69|0.69 |0.69 |0.69 |0.69  |325  |\n",
      "|Substance (substance)                                        |0.73|0.79|0.8  |0.8  |0.8  |0.8   |307  |\n",
      "|Clinical history and observation findings (finding)          |0.7 |0.71|0.72 |0.72 |0.72 |0.72  |178  |\n",
      "|Pharmaceutical / biologic product (product)                  |0.68|0.81|0.82 |0.82 |0.82 |0.82  |170  |\n",
      "|Qualifier value (qualifier value)                            |0.67|0.75|0.75 |0.75 |0.75 |0.75  |124  |\n",
      "|Observable entity (observable entity)                        |0.83|0.86|0.86 |0.86 |0.86 |0.86  |86   |\n",
      "|Situation with explicit context (situation)                  |0.83|0.83|0.83 |0.83 |0.83 |0.83  |60   |\n",
      "|Evaluation finding (finding)                                 |0.47|0.53|0.55 |0.55 |0.55 |0.55  |58   |\n",
      "|Social context (social concept)                              |0.61|0.73|0.8  |0.8  |0.8  |0.8   |51   |\n",
      "|Event (event)                                                |0.76|0.76|0.76 |0.76 |0.76 |0.76  |42   |\n",
      "|Administrative statuses (finding)                            |0.6 |0.6 |0.6  |0.6  |0.6  |0.6   |30   |\n",
      "|Staging and scales (staging scale)                           |0.79|0.79|0.79 |0.79 |0.79 |0.79  |24   |\n",
      "|Specimen (specimen)                                          |0.87|0.87|0.87 |0.87 |0.87 |0.87  |23   |\n",
      "|Neurological finding (finding)                               |0.55|0.55|0.55 |0.55 |0.55 |0.55  |22   |\n",
      "|Finding by method (finding)                                  |0.4 |0.4 |0.4  |0.4  |0.4  |0.4   |20   |\n",
      "|Environment or geographical location (environment / location)|0.78|0.78|0.78 |0.78 |0.78 |0.78  |18   |\n",
      "|SNOMED CT Model Component (metadata)                         |0.57|0.64|0.64 |0.64 |0.64 |0.64  |14   |\n",
      "|Propensity to adverse reaction (finding)                     |0.64|0.64|0.64 |0.64 |0.64 |0.64  |11   |\n",
      "|Wound finding (finding)                                      |0.44|0.44|0.44 |0.44 |0.44 |0.44  |9    |\n",
      "|Special concept (special concept)                            |0.5 |0.5 |0.5  |0.5  |0.5  |0.5   |8    |\n",
      "|Edema (finding)                                              |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |7    |\n",
      "|Record artifact (record artifact)                            |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |6    |\n",
      "|General clinical state finding (finding)                     |0.4 |0.4 |0.4  |0.4  |0.4  |0.4   |5    |\n",
      "|Fetal finding (finding)                                      |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |5    |\n",
      "|Bleeding (finding)                                           |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |4    |\n",
      "|Effect of exposure to physical force (finding)               |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |1    |\n",
      "|Finding reported by subject or history provider (finding)    |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |1    |\n",
      "|Erythema (finding)                                           |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |1    |\n",
      "|Urine finding (finding)                                      |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |1    |\n",
      "|Color finding (finding)                                      |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |1    |\n",
      "|Deformity (finding)                                          |0.0 |0.0 |0.0  |0.0  |0.0  |0.0   |1    |\n",
      "+-------------------------------------------------------------+----+----+-----+-----+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaled.groupby(\"topTerm\").agg(\n",
    "    F.mean(\"good\"), \n",
    "    F.mean(\"hat5\"), \n",
    "    F.mean(\"hat10\"), \n",
    "    F.mean(\"hat20\"), \n",
    "    F.mean(\"hat30\"), \n",
    "    F.mean(\"hat500\"), \n",
    "    F.count(\"good\")).orderBy(\"count(good)\", ascending=False)\\\n",
    ".selectExpr(\"topTerm\",\n",
    "            \"round(`avg(good)`, 2) as good\",\n",
    "            \"round(`avg(hat5)`, 2) as hat5\",\n",
    "            \"round(`avg(hat10)`, 2) as hat10\",\n",
    "            \"round(`avg(hat20)`, 2) as hat20\",\n",
    "            \"round(`avg(hat30)`, 2) as hat30\",\n",
    "            \"round(`avg(hat500)`, 2) as hat500\",\n",
    "            \"`count(good)` as total\")\\\n",
    ".show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.48 minutes\n"
     ]
    }
   ],
   "source": [
    "print(round((time.time()-start)/60, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsl240",
   "language": "python",
   "name": "jsl240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
