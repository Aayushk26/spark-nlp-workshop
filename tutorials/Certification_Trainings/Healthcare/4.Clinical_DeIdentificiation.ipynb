{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I08sFJYCxR0Z"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKI5K1wQrSe9"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentificiation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Niy3mZAjoayg"
   },
   "source": [
    "# Clinical Deidentification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okhT7AcXxben"
   },
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I8Ytt2LLp2rj",
    "outputId": "6254856e-5398-427d-ad7b-bcc099122402"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SECRET', 'SPARK_NLP_LICENSE', 'SPARK_OCR_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET', 'JSL_VERSION', 'PUBLIC_VERSION'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('workshop_license_keys_Aug2020.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_keys['JSL_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BkrtwRnBcnw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JSL_VERSION': 'jjj',\n",
       " 'PUBLIC_VERSION': 'vvv',\n",
       " 'SECRET': 'xxx',\n",
       " 'SPARK_NLP_LICENSE': 'aaa',\n",
       " 'JSL_OCR_LICENSE': 'bbb',\n",
       " 'AWS_ACCESS_KEY_ID': 'ccc',\n",
       " 'AWS_SECRET_ACCESS_KEY': 'ddd',\n",
       " 'JSL_OCR_SECRET': 'eee'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template for license_key.json\n",
    "\n",
    "{'JSL_VERSION':'jjj',\n",
    "'PUBLIC_VERSION':'vvv',\n",
    "'SECRET':\"xxx\",\n",
    "'SPARK_NLP_LICENSE': 'aaa',\n",
    "'JSL_OCR_LICENSE': 'bbb',\n",
    "'AWS_ACCESS_KEY_ID':\"ccc\",\n",
    "'AWS_SECRET_ACCESS_KEY':\"ddd\",\n",
    "'JSL_OCR_SECRET':\"eee\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "xy-mE2aVxZjl",
    "outputId": "d82c93e4-1561-47ad-b814-fbaabb46cdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "2.5.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['SPARK_OCR_LICENSE'] = license_keys['SPARK_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "jsl_version = license_keys['JSL_VERSION']\n",
    "version = license_keys['PUBLIC_VERSION']\n",
    "\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "! pip install --ignore-installed -q spark-nlp==$version\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "print (sparknlp.version())\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to start the session with custom params as in start function above\n",
    "def start(secret):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:\"+version) \\\n",
    "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-\"+jsl_version+\".jar\")\n",
    "      \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "#spark = start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "V1wrGrq0GClP",
    "outputId": "eafce5ec-0a83-4f6f-8cd4-fb1f10d9fae7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.8:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9b97e58400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFQifkFYihOc"
   },
   "source": [
    "# Deidentification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protected Health Information: \n",
    "- individualâ€™s past, present, or future physical or mental health or condition\n",
    "- provision of health care to the individual\n",
    "- past, present, or future payment for the health care \n",
    "\n",
    "Protected health information includes many common identifiers (e.g., name, address, birth date, Social Security Number) when they can be associated with the health information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load NER pipeline to isentify protected entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONMo7NWXU19B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import pyspark.sql.functions as F\n",
    "import string\n",
    "import numpy as np\n",
    "import sparknlp\n",
    "from sparknlp.util import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "from pyspark.sql import functions as F\n",
    "from sparknlp_jsl.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "qHzG7Wvhgcex",
    "outputId": "6ea42b81-47eb-4cf8-8610-801c3bb80907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols([\"sentence\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "  .setInputCols([\"sentence\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)\n",
    "\n",
    "clinical_ner = NerDLModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained NER models extracts:\n",
    "\n",
    "- Name\n",
    "- Profession\n",
    "- Age\n",
    "- Date\n",
    "- Contact(Telephone numbers, FAX numbers, Email addresses)\n",
    "- Location (Address, City, Postal code, Hospital Name, Employment information)\n",
    "- Id (Social Security numbers, Medical record numbers, Internet protocol addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='''\n",
    "A . Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01/13/93 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|ner_label |count|\n",
      "+----------+-----+\n",
      "|O         |28   |\n",
      "|I-LOCATION|5    |\n",
      "|I-NAME    |3    |\n",
      "|B-NAME    |3    |\n",
      "|B-DATE    |3    |\n",
      "|B-LOCATION|2    |\n",
      "|B-AGE     |1    |\n",
      "|B-ID      |1    |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.select(\"token\", \"ner_label\").groupBy('ner_label').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check extracted sensetive entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------+\n",
      "|chunk                        |ner_label|\n",
      "+-----------------------------+---------+\n",
      "|2093-01-13                   |DATE     |\n",
      "|David Hale                   |NAME     |\n",
      "|Hendrickson , Ora            |NAME     |\n",
      "|7194334                      |ID       |\n",
      "|01/13/93                     |DATE     |\n",
      "|Oliveira                     |NAME     |\n",
      "|25                           |AGE      |\n",
      "|2079-11-09                   |DATE     |\n",
      "|Cocke County Baptist Hospital|LOCATION |\n",
      "|0295 Keats Street            |LOCATION |\n",
      "+-----------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the cases, where the model will skip some important entities, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='''\n",
    "Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital. Phone number: (541) 754-3010. MSW 100009632582\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+---------+\n",
      "|chunk                     |ner_label|\n",
      "+--------------------------+---------+\n",
      "|25                        |AGE      |\n",
      "|Beijing                   |LOCATION |\n",
      "|The Johns Hopkins Hospital|LOCATION |\n",
      "|(541) 754-3010            |CONTACT  |\n",
      "|100009632582              |ID       |\n",
      "+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))\n",
    "\n",
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these entities we can add a dictionary to the pipeline, by using **NerOverwriter()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neroverwriter = NerOverwriter() \\\n",
    "    .setInputCols([\"ner\"]) \\\n",
    "    .setOutputCol(\"ner_overwrited\") \\\n",
    "    .setStopWords(['AIQING']) \\\n",
    "    .setNewResult(\"I-NAME\")\n",
    "\n",
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner_overwrited\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    neroverwriter,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model after modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+---------+\n",
      "|chunk                     |ner_label|\n",
      "+--------------------------+---------+\n",
      "|AIQING                    |NAME     |\n",
      "|25                        |AGE      |\n",
      "|Beijing                   |LOCATION |\n",
      "|The Johns Hopkins Hospital|LOCATION |\n",
      "|(541) 754-3010            |CONTACT  |\n",
      "|100009632582              |ID       |\n",
      "+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))\n",
    "\n",
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, now name **AIQING** was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding entities from deidentification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we need to leave some entities in the text, for example, if we want to analyze the frequency of the disease by the hospital. In this case, we need to use parameter **setWhiteList()** to modify NerChunk output. This parameter having using a list of entities type to deidentify as an input. So, if we want to leave the location in the list we need to remove this tag from the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner_overwrited\"])\\\n",
    "  .setOutputCol(\"ner_chunk\") \\\n",
    "  .setWhiteList(['NAME', 'PROFESSION', 'ID', 'AGE',\n",
    "               'DATE', 'CONTACT'])\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    neroverwriter,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model_with_white_list = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_white_list = model_with_white_list.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|chunk         |ner_label|\n",
      "+--------------+---------+\n",
      "|AIQING        |NAME     |\n",
      "|25            |AGE      |\n",
      "|(541) 754-3010|CONTACT  |\n",
      "|100009632582  |ID       |\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))\n",
    "\n",
    "result_with_white_list.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and Obfuscation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace this enitites with Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WaFe5bZzhEXT",
    "outputId": "d6a0f2e9-0a82-4f2a-8ee0-5c63503e3241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deidentify_large download started this may take some time.\n",
      "Approximate size to download 188.1 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "deidentification = DeIdentificationModel.pretrained(\"deidentify_large\", \"en\", \"clinical/models\") \\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "      .setOutputCol(\"deidentified\") \\\n",
    "      .setMode(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "deid_text = deidentification.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.</td>\n",
       "      <td>Patient &lt;NAME&gt;, &lt;AGE&gt; month years-old , born in &lt;LOCATION&gt;, was transfered to the &lt;LOCATION&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phone number: (541) 754-3010.</td>\n",
       "      <td>Phone number: &lt;CONTACT&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSW 100009632582</td>\n",
       "      <td>MSW &lt;ID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  sentence                                                                                   deidentified\n",
       "0  Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.  Patient <NAME>, <AGE> month years-old , born in <LOCATION>, was transfered to the <LOCATION>.\n",
       "1  Phone number: (541) 754-3010.                                                                            Phone number: <CONTACT>.                                                                     \n",
       "2  MSW 100009632582                                                                                         MSW <ID>                                                                                     "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deid_text.select(F.explode(F.arrays_zip('sentence.result', 'deidentified.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use obfuscation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the obfuscation mode **DeIdentificationModel** will replace sensetive entities with random values of the same type. \n",
    "\n",
    "Will be replaced: \n",
    "- Name\n",
    "- Date\n",
    "- Location\n",
    "- Contacts\n",
    "- Profession\n",
    "\n",
    "Will be tagged:\n",
    "- Age\n",
    "- ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deidentify_large download started this may take some time.\n",
      "Approximate size to download 188.1 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "obfuscation = DeIdentificationModel.pretrained(\"deidentify_large\", \"en\", \"clinical/models\") \\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "      .setOutputCol(\"deidentified\") \\\n",
    "      .setMode(\"obfuscate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfusated_text = obfuscation.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.</td>\n",
       "      <td>Patient NANCY, &lt;AGE&gt; month years-old , born in Bellflower, was transfered to the Canutillo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phone number: (541) 754-3010.</td>\n",
       "      <td>Phone number: (608)378-7979.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSW 100009632582</td>\n",
       "      <td>MSW &lt;ID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  sentence                                                                                 deidentified\n",
       "0  Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.  Patient NANCY, <AGE> month years-old , born in Bellflower, was transfered to the Canutillo.\n",
       "1  Phone number: (541) 754-3010.                                                                            Phone number: (608)378-7979.                                                               \n",
       "2  MSW 100009632582                                                                                         MSW <ID>                                                                                   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfusated_text.select(F.explode(F.arrays_zip('sentence.result', 'deidentified.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use full pipeline in the Light model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "finisher = Finisher() \\\n",
    "    .setInputCols(\"deidentified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qhq7n1IahS_Y"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    neroverwriter,\n",
    "    ner_converter,\n",
    "    obfuscation,\n",
    "    finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhtnLajzgNNb"
   },
   "outputs": [],
   "source": [
    "light_model = LightPipeline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sC_bn1Hhs9g"
   },
   "outputs": [],
   "source": [
    "text ='''\n",
    "A . Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01-13-1993 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "jbblkrvjEHn9",
    "outputId": "d11526e2-2f58-45b3-f415-aa451e85a174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A .',\n",
       " 'Record date : 2093-01-30 , Crawford , M.D .',\n",
       " ', Name : Nero MR .',\n",
       " '# <ID> Date : 03-05-1993 PCP : Jeannette , <AGE> month years-old , Record date : 2079-12-30 .',\n",
       " 'Cocke County Baptist Hospital .',\n",
       " '<ID> Keats Street']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_text = light_model.annotate(text)\n",
    "annotated_text['deidentified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "0emrh9kBfRKf",
    "outputId": "206b3d00-6540-44ad-b4ea-287a2c00d06c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Record date : 2093-02-08, Adlai, M.D. is Singers, \\nName: Blythe MR. # <ID> Date: (312)355-3103 PCP: Letisha.',\n",
       " 'Record date: 2079-12-08.',\n",
       " 'Cocke County Baptist Hospital.',\n",
       " '<ID> Keats Street.',\n",
       " 'This <AGE> male, presented with chest heaviness that started during a pick-up basketball game.',\n",
       " 'His past medical history was unremarkable.',\n",
       " 'He denied prior cardiac symptoms and suffered no chest trauma during the game.',\n",
       " 'His father had suffered an acute myocardial infarction at age',\n",
       " '<AGE>. The patient was a nonsmoker, did not drink alcohol, and denied recreational drug use.',\n",
       " 'He swallowed a tablet of aspirin before coming to the emergency room.',\n",
       " 'His blood pressure was 160/90 mm Hg, and his heart rate was 80 bpm.',\n",
       " 'Physical examination revealed no stigmata of Marfan syndrome.',\n",
       " 'The rest of his physical examination was normal.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text = '''Record date : 2093-01-13, David Hale, M.D. is manager, \n",
    "Name: Hendrickson, Ora MR. # 7194334 Date: 01-13-1993 PCP: Oliveira.\n",
    "Record date: 2079-11-09. Cocke County Baptist Hospital. 0295 Keats Street.\n",
    "This 17-yr-old male, presented with chest heaviness that started during a pick-up basketball game. His past medical history was unremarkable. He denied prior cardiac symptoms and suffered no chest trauma during the game. His father had suffered an acute myocardial infarction at age 38. The patient was a nonsmoker, did not drink alcohol, and denied recreational drug use. He swallowed a tablet of aspirin before coming to the emergency room. His blood pressure was 160/90 mm Hg, and his heart rate was 80 bpm. Physical examination revealed no stigmata of Marfan syndrome. The rest of his physical examination was normal.'''\n",
    "\n",
    "annotated_text = light_model.annotate(source_text)\n",
    "annotated_text['deidentified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train custom NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-03 19:50:26--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.train\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3283420 (3.1M) [text/plain]\n",
      "Saving to: â€˜eng.train.6â€™\n",
      "\n",
      "eng.train.6         100%[===================>]   3.13M  2.78MB/s    in 1.1s    \n",
      "\n",
      "2020-08-03 19:50:27 (2.78 MB/s) - â€˜eng.train.6â€™ saved [3283420/3283420]\n",
      "\n",
      "--2020-08-03 19:50:27--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.testa\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.132.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.132.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 827443 (808K) [text/plain]\n",
      "Saving to: â€˜eng.testa.6â€™\n",
      "\n",
      "eng.testa.6         100%[===================>] 808.05K  4.12MB/s    in 0.2s    \n",
      "\n",
      "2020-08-03 19:50:28 (4.12 MB/s) - â€˜eng.testa.6â€™ saved [827443/827443]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.train\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.testa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "\n",
    "training_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|ground_truth|count |\n",
      "+------------+------+\n",
      "|O           |169578|\n",
      "|B-LOC       |7140  |\n",
      "|B-PER       |6600  |\n",
      "|B-ORG       |6321  |\n",
      "|I-PER       |4528  |\n",
      "|I-ORG       |3704  |\n",
      "|B-MISC      |3438  |\n",
      "|I-LOC       |1157  |\n",
      "|I-MISC      |1155  |\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "training_data.select(F.explode(F.arrays_zip('token.result','label.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ground_truth\")).groupBy('ground_truth').count().orderBy('count', ascending=False).show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# You can use any word embeddings you want (Glove, Elmo, Bert, custom etc.)\n",
    "\n",
    "glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
    "          .setInputCols([\"document\", \"token\"])\\\n",
    "          .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 Âµs, sys: 1 Âµs, total: 6 Âµs\n",
      "Wall time: 11.9 Âµs\n"
     ]
    }
   ],
   "source": [
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(2)\\\n",
    "  .setLr(0.001)\\\n",
    "  .setPo(0.005)\\\n",
    "  .setBatchSize(32)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(1)\\\n",
    "  .setValidationSplit(0.2)\\\n",
    "  .setEvaluationLogExtended(True) \\\n",
    "  .setEnableOutputLogs(True)\\\n",
    "  .setIncludeConfidence(True)\\\n",
    "  #.setOutputLogsPath('./')\n",
    "\n",
    "ner_pipeline = Pipeline(stages=[\n",
    "          glove_embeddings,\n",
    "          nerTagger\n",
    " ])\n",
    "\n",
    "%time\n",
    "ner_model = ner_pipeline.fit(training_data)\n",
    "\n",
    "# if you get an error for incompatible TF graph, use 4.1 NerDL-Graph.ipynb notebook to create a graph from public repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    glove_embeddings,\n",
    "    ner_model.stages[1],\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "custom_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = '''Record date : 2093-01-13, David Hale, M.D. is manager from The European Commission'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = custom_model.transform(spark.createDataFrame([[source_text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We got new entities in the model 'PER' and 'ORG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|chunk              |ner_label|\n",
      "+-------------------+---------+\n",
      "|David Hale         |PER      |\n",
      "|M.D                |PER      |\n",
      "|European Commission|MISC     |\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be able to obfuscate new entities we have to create custom Deidentification Model with new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_identification = DeIdentification() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "    .setOutputCol(\"deidentified\") \\\n",
    "    .setMode('obfuscate') \\\n",
    "    .setObfuscateRefFile('obfuscation.txt') \\\n",
    "    .setRefSep('#') \\\n",
    "    .setRegexPatternsDictionary('regex_dict.txt', 'TEXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "deid_model = de_identification.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "deid_text = deid_model.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Record date : 2093-01-13, David Hale, M.D. is manager from The European Commission</td>\n",
       "      <td>Record date : 2093-01-13, ARLYN COLEY, ARLYN COLEY. is manager from The Durham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             sentence                                                                    deidentified\n",
       "0  Record date : 2093-01-13, David Hale, M.D. is manager from The European Commission  Record date : 2093-01-13, ARLYN COLEY, ARLYN COLEY. is manager from The Durham"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deid_text.select(F.explode(F.arrays_zip('sentence.result', 'deidentified.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4.Clinical_DeIdentificiation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
