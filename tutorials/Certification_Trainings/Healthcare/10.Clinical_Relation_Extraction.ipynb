{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posology Demo\n",
    "\n",
    "This is a demonstration of using SparkNLP for extracting posology relations. The following relatios are supported:\n",
    "\n",
    "DRUG-DOSAGE\n",
    "DRUG-FREQUENCY\n",
    "DRUG-ADE (Adversed Drug Events)\n",
    "DRUG-FORM\n",
    "DRUG-ROUTE\n",
    "DRUG-DURATION\n",
    "DRUG-REASON\n",
    "DRUG=STRENGTH\n",
    "\n",
    "The model has been validated agains the posology dataset described in (Magge, Scotch, & Gonzalez-Hernandez, 2018).\n",
    "\n",
    "| Relation | Recall | Precision | F1 | F1 (Magge, Scotch, & Gonzalez-Hernandez, 2018) |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| DRUG-ADE | 0.66 | 1.00 | **0.80** | 0.76 |\n",
    "| DRUG-DOSAGE | 0.89 | 1.00 | **0.94** | 0.91 |\n",
    "| DRUG-DURATION | 0.75 | 1.00 | **0.85** | 0.92 |\n",
    "| DRUG-FORM | 0.88 | 1.00 | **0.94** | 0.95* |\n",
    "| DRUG-FREQUENCY | 0.79 | 1.00 | **0.88** | 0.90 |\n",
    "| DRUG-REASON | 0.60 | 1.00 | **0.75** | 0.70 |\n",
    "| DRUG-ROUTE | 0.79 | 1.00 | **0.88** | 0.95* |\n",
    "| DRUG-STRENGTH | 0.95 | 1.00 | **0.98** | 0.97 |\n",
    "\n",
    "\n",
    "*Magge, Scotch, Gonzalez-Hernandez (2018) collapsed DRUG-FORM and DRUG-ROUTE into a single relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:18:58.500653Z",
     "start_time": "2020-07-31T14:18:58.219349Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pyspark\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "import functools \n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:18:59.071372Z",
     "start_time": "2020-07-31T14:18:59.056971Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/home/i/jsl_license.json', 'r') as json_file:\n",
    "    license_keys = json.load(json_file)\n",
    "    \n",
    "secret = license_keys['secret']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:19:05.345002Z",
     "start_time": "2020-07-31T14:18:59.800724Z"
    }
   },
   "outputs": [],
   "source": [
    "def start(secret):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.3\") \\\n",
    "        .config(\"spark.jars\", \"../lib/sparknlp-jsl.jar\")\n",
    "      \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "spark = start(license_keys[\"secret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build pipeline using SparNLP pretrained models and the relation extration model optimized for posology**.\n",
    " \n",
    " The precision of the RE model is controlled by \"setMaxSyntacticDistance(4)\", which sets the maximum syntactic distance between named entities to 4. A larger value will improve recall at the expense at lower precision. A value of 4 leads to literally perfect precision (i.e. the model doesn't produce any false positives) and reasonably good recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:19:37.196164Z",
     "start_time": "2020-07-31T14:19:09.356386Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "pos_clinical download started this may take some time.\n",
      "Approximate size to download 1.7 MB\n",
      "[OK!]\n",
      "ner_posology download started this may take some time.\n",
      "Approximate size to download 13.7 MB\n",
      "[OK!]\n",
      "dependency_conllu download started this may take some time.\n",
      "Approximate size to download 16.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documenter = sparknlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentencer = sparknlp.annotators.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentences\")\n",
    "\n",
    "tokenizer = sparknlp.annotators.Tokenizer()\\\n",
    "    .setInputCols([\"sentences\"])\\\n",
    "    .setOutputCol(\"tokens\")\n",
    "\n",
    "words_embedder = sparknlp.annotators.WordEmbeddingsModel()\\\n",
    "    .pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentences\", \"tokens\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "pos_tagger = sparknlp.annotators.PerceptronModel()\\\n",
    "    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentences\", \"tokens\"])\\\n",
    "    .setOutputCol(\"pos_tags\")\n",
    "\n",
    "ner_tagger = sparknlp.annotators.NerDLModel()\\\n",
    "    .pretrained(\"ner_posology\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"sentences\", \"tokens\", \"embeddings\")\\\n",
    "    .setOutputCol(\"ner_tags\")    \n",
    "\n",
    "ner_chunker = sparknlp.annotators.NerConverter()\\\n",
    "    .setInputCols([\"sentences\", \"tokens\", \"ner_tags\"])\\\n",
    "    .setOutputCol(\"ner_chunks\")\n",
    "\n",
    "dependency_parser = sparknlp.annotators.DependencyParserModel()\\\n",
    "    .pretrained(\"dependency_conllu\", \"en\")\\\n",
    "    .setInputCols([\"document\", \"pos_tags\", \"tokens\"])\\\n",
    "    .setOutputCol(\"dependencies\")\n",
    "\n",
    "reModel = sparknlp_jsl.annotator.RelationExtractionModel()\\\n",
    "    .pretrained(\"posology_re\", \"en\")\\\n",
    "    .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunks\", \"dependencies\"])\\\n",
    "    .setOutputCol(\"relations\")\\\n",
    "    .setMaxSyntacticDistance(4)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    documenter,\n",
    "    sentencer,\n",
    "    tokenizer, \n",
    "    words_embedder, \n",
    "    pos_tagger, \n",
    "    ner_tagger,\n",
    "    ner_chunker,\n",
    "    dependency_parser,\n",
    "    reModel\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create empty dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T10:09:32.462913Z",
     "start_time": "2020-07-17T10:09:32.410488Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = T.StructType([T.StructField(\"text\", T.StringType(), True)])\n",
    "empty_df = spark.createDataFrame([],schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a light pipeline for annotating free text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T10:24:30.899532Z",
     "start_time": "2020-07-17T10:09:32.894746Z"
    }
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(empty_df)\n",
    "lmodel = sparknlp.base.LightPipeline(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample free text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T11:18:31.409708Z",
     "start_time": "2020-07-17T11:18:31.336534Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also \n",
    "given 1 unit of Metformin daily.\n",
    "He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , \n",
    "12 units of insulin lispro with meals , and metformin 1000 mg two times a day.\n",
    "\"\"\"\n",
    "results = lmodel.fullAnnotate(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show extracted relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T10:29:26.101405Z",
     "start_time": "2020-07-17T10:29:26.012555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOSAGE-DRUG(DOSAGE=1 unit - DRUG=Advil)\n",
      "DRUG-DURATION(DRUG=Advil - DURATION=for 5 days)\n",
      "DOSAGE-DRUG(DOSAGE=1 unit - DRUG=Metformin)\n",
      "DRUG-FREQUENCY(DRUG=Metformin - FREQUENCY=daily)\n",
      "DOSAGE-DRUG(DOSAGE=40 units - DRUG=insulin glargine)\n",
      "DRUG-FREQUENCY(DRUG=insulin glargine - FREQUENCY=at night)\n",
      "DOSAGE-DRUG(DOSAGE=12 units - DRUG=insulin lispro)\n",
      "DRUG-FREQUENCY(DRUG=insulin lispro - FREQUENCY=with meals)\n",
      "DRUG-STRENGTH(DRUG=metformin - STRENGTH=1000 mg)\n",
      "DRUG-FREQUENCY(DRUG=metformin - FREQUENCY=two times a day)\n"
     ]
    }
   ],
   "source": [
    "for rel in results[0][\"relations\"]:\n",
    "    print(\"{}({}={} - {}={})\".format(\n",
    "        rel.result, \n",
    "        rel.metadata['entity1'], \n",
    "        rel.metadata['chunk1'], \n",
    "        rel.metadata['entity2'],\n",
    "        rel.metadata['chunk2']\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
